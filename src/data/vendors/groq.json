[
  {
    "id": 7,
    "systemName": "llama-3-70b-8192",
    "displayName": "Llama 3 70B",
    "categoryId": 2,
    "parametersB": 70,
    "vendorId": 4,
    "host": "api.groq.com",
    "precision": "BF16",
    "description": "Meta's Llama 3 70B model running on Groq's LPU Inference Engine for extremely fast inference.",
    "contextWindow": 8192,
    "tokenLimit": 4096,
    "releaseDate": "2024-04-18",
    "isOpenSource": false,
    "isHidden": false,
    "pricing": {
      "id": 7,
      "modelId": 7,
      "inputText": 0.59,
      "outputText": 0.79
    }
  },
  {
    "id": 8,
    "systemName": "mixtral-8x7b-32768",
    "displayName": "Mixtral 8x7B",
    "categoryId": 2,
    "parametersB": 56,
    "vendorId": 4,
    "host": "api.groq.com",
    "precision": "BF16",
    "description": "Mistral AI's Mixtral 8x7B model running on Groq's LPU Inference Engine.",
    "contextWindow": 32768,
    "tokenLimit": 4096,
    "releaseDate": "2023-12-15",
    "isOpenSource": false,
    "isHidden": true,
    "pricing": {
      "id": 8,
      "modelId": 8,
      "inputText": 0.24,
      "outputText": 0.24
    }
  }
]